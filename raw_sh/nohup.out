usage: train.py [-h] [-config CONFIG] [-save_config SAVE_CONFIG]
                [--src_word_vec_size SRC_WORD_VEC_SIZE]
                [--tgt_word_vec_size TGT_WORD_VEC_SIZE]
                [--word_vec_size WORD_VEC_SIZE] [--share_decoder_embeddings]
                [--share_embeddings] [--position_encoding]
                [--feat_merge {concat,sum,mlp}]
                [--feat_vec_size FEAT_VEC_SIZE]
                [--feat_vec_exponent FEAT_VEC_EXPONENT]
                [--model_type {text,img,audio,vec}]
                [--model_dtype {fp32,fp16}]
                [--encoder_type {rnn,brnn,ggnn,mean,transformer,cnn,biattention}]
                [--decoder_type {rnn,transformer,cnn}] [--layers LAYERS]
                [--enc_layers ENC_LAYERS] [--dec_layers DEC_LAYERS]
                [--rnn_size RNN_SIZE] [--enc_rnn_size ENC_RNN_SIZE]
                [--dec_rnn_size DEC_RNN_SIZE]
                [--audio_enc_pooling AUDIO_ENC_POOLING]
                [--cnn_kernel_width CNN_KERNEL_WIDTH]
                [--input_feed INPUT_FEED] [--bridge]
                [--rnn_type {LSTM,GRU,SRU}] [--brnn]
                [--context_gate {source,target,both}]
                [--bridge_extra_node BRIDGE_EXTRA_NODE]
                [--bidir_edges BIDIR_EDGES] [--state_dim STATE_DIM]
                [--n_edge_types N_EDGE_TYPES] [--n_node N_NODE]
                [--n_steps N_STEPS] [--src_vocab SRC_VOCAB]
                [--global_attention {dot,general,mlp,none}]
                [--global_attention_function {softmax,sparsemax}]
                [--self_attn_type SELF_ATTN_TYPE]
                [--max_relative_positions MAX_RELATIVE_POSITIONS]
                [--heads HEADS] [--transformer_ff TRANSFORMER_FF]
                [--aan_useffn] [--lambda_align LAMBDA_ALIGN]
                [--alignment_layer ALIGNMENT_LAYER]
                [--alignment_heads ALIGNMENT_HEADS] [--full_context_alignment]
                [--copy_attn] [--copy_attn_type {dot,general,mlp,none}]
                [--generator_function {softmax,sparsemax}] [--copy_attn_force]
                [--reuse_copy_attn] [--copy_loss_by_seqlength]
                [--coverage_attn] [--lambda_coverage LAMBDA_COVERAGE]
                [--loss_scale LOSS_SCALE] [--apex_opt_level {O0,O1,O2,O3}]
                --data DATA [--data_ids DATA_IDS [DATA_IDS ...]]
                [--data_weights DATA_WEIGHTS [DATA_WEIGHTS ...]]
                [--data_to_noise DATA_TO_NOISE [DATA_TO_NOISE ...]]
                [--save_model SAVE_MODEL]
                [--save_checkpoint_steps SAVE_CHECKPOINT_STEPS]
                [--keep_checkpoint KEEP_CHECKPOINT]
                [--gpuid [GPUID [GPUID ...]]]
                [--gpu_ranks [GPU_RANKS [GPU_RANKS ...]]]
                [--world_size WORLD_SIZE] [--gpu_backend GPU_BACKEND]
                [--gpu_verbose_level GPU_VERBOSE_LEVEL]
                [--master_ip MASTER_IP] [--master_port MASTER_PORT]
                [--queue_size QUEUE_SIZE] [--seed SEED]
                [--param_init PARAM_INIT] [--param_init_glorot]
                [--train_from TRAIN_FROM]
                [--reset_optim {none,all,states,keep_states}]
                [--pre_word_vecs_enc PRE_WORD_VECS_ENC]
                [--pre_word_vecs_dec PRE_WORD_VECS_DEC] [--fix_word_vecs_enc]
                [--fix_word_vecs_dec] [--batch_size BATCH_SIZE]
                [--batch_type {sents,tokens}] [--pool_factor POOL_FACTOR]
                [--normalization {sents,tokens}]
                [--accum_count ACCUM_COUNT [ACCUM_COUNT ...]]
                [--accum_steps ACCUM_STEPS [ACCUM_STEPS ...]]
                [--valid_steps VALID_STEPS]
                [--valid_batch_size VALID_BATCH_SIZE]
                [--max_generator_batches MAX_GENERATOR_BATCHES]
                [--train_steps TRAIN_STEPS] [--single_pass] [--epochs EPOCHS]
                [--early_stopping EARLY_STOPPING]
                [--early_stopping_criteria [EARLY_STOPPING_CRITERIA [EARLY_STOPPING_CRITERIA ...]]]
                [--optim {sgd,adagrad,adadelta,adam,sparseadam,adafactor,fusedadam}]
                [--adagrad_accumulator_init ADAGRAD_ACCUMULATOR_INIT]
                [--max_grad_norm MAX_GRAD_NORM]
                [--dropout DROPOUT [DROPOUT ...]]
                [--attention_dropout ATTENTION_DROPOUT [ATTENTION_DROPOUT ...]]
                [--dropout_steps DROPOUT_STEPS [DROPOUT_STEPS ...]]
                [--truncated_decoder TRUNCATED_DECODER]
                [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
                [--label_smoothing LABEL_SMOOTHING]
                [--average_decay AVERAGE_DECAY]
                [--average_every AVERAGE_EVERY]
                [--src_noise {sen_shuffling,infilling,mask} [{sen_shuffling,infilling,mask} ...]]
                [--src_noise_prob SRC_NOISE_PROB [SRC_NOISE_PROB ...]]
                [--learning_rate LEARNING_RATE]
                [--learning_rate_decay LEARNING_RATE_DECAY]
                [--start_decay_steps START_DECAY_STEPS]
                [--decay_steps DECAY_STEPS]
                [--decay_method {noam,noamwd,rsqrt,none}]
                [--warmup_steps WARMUP_STEPS] [--report_every REPORT_EVERY]
                [--log_file LOG_FILE]
                [--log_file_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET,50,40,30,20,10,0}]
                [--exp_host EXP_HOST] [--exp EXP] [--tensorboard]
                [--tensorboard_log_dir TENSORBOARD_LOG_DIR]
                [--sample_rate SAMPLE_RATE] [--window_size WINDOW_SIZE]
                [--image_channel_size {3,1}]
train.py: error: the following arguments are required: --data/-data
usage: train.py [-h] [-config CONFIG] [-save_config SAVE_CONFIG]
                [--src_word_vec_size SRC_WORD_VEC_SIZE]
                [--tgt_word_vec_size TGT_WORD_VEC_SIZE]
                [--word_vec_size WORD_VEC_SIZE] [--share_decoder_embeddings]
                [--share_embeddings] [--position_encoding]
                [--feat_merge {concat,sum,mlp}]
                [--feat_vec_size FEAT_VEC_SIZE]
                [--feat_vec_exponent FEAT_VEC_EXPONENT]
                [--model_type {text,img,audio,vec}]
                [--model_dtype {fp32,fp16}]
                [--encoder_type {rnn,brnn,ggnn,mean,transformer,cnn,biattention}]
                [--decoder_type {rnn,transformer,cnn}] [--layers LAYERS]
                [--enc_layers ENC_LAYERS] [--dec_layers DEC_LAYERS]
                [--rnn_size RNN_SIZE] [--enc_rnn_size ENC_RNN_SIZE]
                [--dec_rnn_size DEC_RNN_SIZE]
                [--audio_enc_pooling AUDIO_ENC_POOLING]
                [--cnn_kernel_width CNN_KERNEL_WIDTH]
                [--input_feed INPUT_FEED] [--bridge]
                [--rnn_type {LSTM,GRU,SRU}] [--brnn]
                [--context_gate {source,target,both}]
                [--bridge_extra_node BRIDGE_EXTRA_NODE]
                [--bidir_edges BIDIR_EDGES] [--state_dim STATE_DIM]
                [--n_edge_types N_EDGE_TYPES] [--n_node N_NODE]
                [--n_steps N_STEPS] [--src_vocab SRC_VOCAB]
                [--global_attention {dot,general,mlp,none}]
                [--global_attention_function {softmax,sparsemax}]
                [--self_attn_type SELF_ATTN_TYPE]
                [--max_relative_positions MAX_RELATIVE_POSITIONS]
                [--heads HEADS] [--transformer_ff TRANSFORMER_FF]
                [--aan_useffn] [--lambda_align LAMBDA_ALIGN]
                [--alignment_layer ALIGNMENT_LAYER]
                [--alignment_heads ALIGNMENT_HEADS] [--full_context_alignment]
                [--copy_attn] [--copy_attn_type {dot,general,mlp,none}]
                [--generator_function {softmax,sparsemax}] [--copy_attn_force]
                [--reuse_copy_attn] [--copy_loss_by_seqlength]
                [--coverage_attn] [--lambda_coverage LAMBDA_COVERAGE]
                [--loss_scale LOSS_SCALE] [--apex_opt_level {O0,O1,O2,O3}]
                --data DATA [--data_ids DATA_IDS [DATA_IDS ...]]
                [--data_weights DATA_WEIGHTS [DATA_WEIGHTS ...]]
                [--data_to_noise DATA_TO_NOISE [DATA_TO_NOISE ...]]
                [--save_model SAVE_MODEL]
                [--save_checkpoint_steps SAVE_CHECKPOINT_STEPS]
                [--keep_checkpoint KEEP_CHECKPOINT]
                [--gpuid [GPUID [GPUID ...]]]
                [--gpu_ranks [GPU_RANKS [GPU_RANKS ...]]]
                [--world_size WORLD_SIZE] [--gpu_backend GPU_BACKEND]
                [--gpu_verbose_level GPU_VERBOSE_LEVEL]
                [--master_ip MASTER_IP] [--master_port MASTER_PORT]
                [--queue_size QUEUE_SIZE] [--seed SEED]
                [--param_init PARAM_INIT] [--param_init_glorot]
                [--train_from TRAIN_FROM]
                [--reset_optim {none,all,states,keep_states}]
                [--pre_word_vecs_enc PRE_WORD_VECS_ENC]
                [--pre_word_vecs_dec PRE_WORD_VECS_DEC] [--fix_word_vecs_enc]
                [--fix_word_vecs_dec] [--batch_size BATCH_SIZE]
                [--batch_type {sents,tokens}] [--pool_factor POOL_FACTOR]
                [--normalization {sents,tokens}]
                [--accum_count ACCUM_COUNT [ACCUM_COUNT ...]]
                [--accum_steps ACCUM_STEPS [ACCUM_STEPS ...]]
                [--valid_steps VALID_STEPS]
                [--valid_batch_size VALID_BATCH_SIZE]
                [--max_generator_batches MAX_GENERATOR_BATCHES]
                [--train_steps TRAIN_STEPS] [--single_pass] [--epochs EPOCHS]
                [--early_stopping EARLY_STOPPING]
                [--early_stopping_criteria [EARLY_STOPPING_CRITERIA [EARLY_STOPPING_CRITERIA ...]]]
                [--optim {sgd,adagrad,adadelta,adam,sparseadam,adafactor,fusedadam}]
                [--adagrad_accumulator_init ADAGRAD_ACCUMULATOR_INIT]
                [--max_grad_norm MAX_GRAD_NORM]
                [--dropout DROPOUT [DROPOUT ...]]
                [--attention_dropout ATTENTION_DROPOUT [ATTENTION_DROPOUT ...]]
                [--dropout_steps DROPOUT_STEPS [DROPOUT_STEPS ...]]
                [--truncated_decoder TRUNCATED_DECODER]
                [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
                [--label_smoothing LABEL_SMOOTHING]
                [--average_decay AVERAGE_DECAY]
                [--average_every AVERAGE_EVERY]
                [--src_noise {sen_shuffling,infilling,mask} [{sen_shuffling,infilling,mask} ...]]
                [--src_noise_prob SRC_NOISE_PROB [SRC_NOISE_PROB ...]]
                [--learning_rate LEARNING_RATE]
                [--learning_rate_decay LEARNING_RATE_DECAY]
                [--start_decay_steps START_DECAY_STEPS]
                [--decay_steps DECAY_STEPS]
                [--decay_method {noam,noamwd,rsqrt,none}]
                [--warmup_steps WARMUP_STEPS] [--report_every REPORT_EVERY]
                [--log_file LOG_FILE]
                [--log_file_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET,50,40,30,20,10,0}]
                [--exp_host EXP_HOST] [--exp EXP] [--tensorboard]
                [--tensorboard_log_dir TENSORBOARD_LOG_DIR]
                [--sample_rate SAMPLE_RATE] [--window_size WINDOW_SIZE]
                [--image_channel_size {3,1}]
train.py: error: the following arguments are required: --data/-data
Total files number: 8676
The top_k 1: 0.261872 acc, 0.082411 recall, 0.125369 f measure,  0.106558 map
The top_k 5: 0.155924 acc, 0.245348 recall, 0.190672 f measure,  0.129112 map
The top_k 10: 0.100599 acc, 0.316587 recall, 0.152682 f measure,  0.131099 map
The top_k 15: 0.074212 acc, 0.350321 recall, 0.122479 f measure,  0.130902 map
The total character size: 143

ROUGE-top 1
{'ROUGE-1-F': 0.12568,
 'ROUGE-1-F-cf95': (0.12034, 0.13116),
 'ROUGE-1-P': 0.13766,
 'ROUGE-1-R': 0.12165,
 'ROUGE-1-R-cf95': (0.11626, 0.12717),
 'ROUGE-2-F': 0.04757,
 'ROUGE-2-F-cf95': (0.04397, 0.05115),
 'ROUGE-2-P': 0.04625,
 'ROUGE-2-R': 0.05218,
 'ROUGE-2-R-cf95': (0.0484, 0.05612),
 'ROUGE-L-F': 0.12552,
 'ROUGE-L-F-cf95': (0.12014, 0.13107),
 'ROUGE-L-P': 0.13749,
 'ROUGE-L-R': 0.12148,
 'ROUGE-L-R-cf95': (0.11612, 0.12693),
 'ROUGE-SU4-F': 0.049,
 'ROUGE-SU4-F-cf95': (0.04537, 0.0526),
 'ROUGE-SU4-P': 0.04877,
 'ROUGE-SU4-R': 0.05441,
 'ROUGE-SU4-R-cf95': (0.05053, 0.05843)}
usage: train.py [-h] [-config CONFIG] [-save_config SAVE_CONFIG]
                [--src_word_vec_size SRC_WORD_VEC_SIZE]
                [--tgt_word_vec_size TGT_WORD_VEC_SIZE]
                [--word_vec_size WORD_VEC_SIZE] [-max_src_len MAX_SRC_LEN]
                [-max_conv_len MAX_CONV_LEN] [--share_decoder_embeddings]
                [--share_embeddings] [--position_encoding]
                [--feat_merge {concat,sum,mlp}]
                [--feat_vec_size FEAT_VEC_SIZE]
                [--feat_vec_exponent FEAT_VEC_EXPONENT]
                [--model_type {text,img,audio,vec}]
                [--model_dtype {fp32,fp16}]
                [--encoder_type {rnn,brnn,ggnn,mean,transformer,cnn,biattention}]
                [--decoder_type {rnn,transformer,cnn}] [--layers LAYERS]
                [--enc_layers ENC_LAYERS] [--dec_layers DEC_LAYERS]
                [--rnn_size RNN_SIZE] [--enc_rnn_size ENC_RNN_SIZE]
                [--dec_rnn_size DEC_RNN_SIZE]
                [--audio_enc_pooling AUDIO_ENC_POOLING]
                [--cnn_kernel_width CNN_KERNEL_WIDTH]
                [--input_feed INPUT_FEED] [--bridge]
                [--rnn_type {LSTM,GRU,SRU}] [--brnn]
                [--context_gate {source,target,both}]
                [--bridge_extra_node BRIDGE_EXTRA_NODE]
                [--bidir_edges BIDIR_EDGES] [--state_dim STATE_DIM]
                [--n_edge_types N_EDGE_TYPES] [--n_node N_NODE]
                [--n_steps N_STEPS] [--src_vocab SRC_VOCAB]
                [--global_attention {dot,general,mlp,none}]
                [--global_attention_function {softmax,sparsemax}]
                [--self_attn_type SELF_ATTN_TYPE]
                [--max_relative_positions MAX_RELATIVE_POSITIONS]
                [--heads HEADS] [--transformer_ff TRANSFORMER_FF]
                [--aan_useffn] [--lambda_align LAMBDA_ALIGN]
                [--alignment_layer ALIGNMENT_LAYER]
                [--alignment_heads ALIGNMENT_HEADS] [--full_context_alignment]
                [--copy_attn] [--copy_attn_type {dot,general,mlp,none}]
                [--generator_function {softmax,sparsemax}] [--copy_attn_force]
                [--reuse_copy_attn] [--copy_loss_by_seqlength]
                [--coverage_attn] [--lambda_coverage LAMBDA_COVERAGE]
                [--loss_scale LOSS_SCALE] [--apex_opt_level {O0,O1,O2,O3}]
                --data DATA [--data_ids DATA_IDS [DATA_IDS ...]]
                [--data_weights DATA_WEIGHTS [DATA_WEIGHTS ...]]
                [--data_to_noise DATA_TO_NOISE [DATA_TO_NOISE ...]]
                [--save_model SAVE_MODEL]
                [--save_checkpoint_steps SAVE_CHECKPOINT_STEPS]
                [--keep_checkpoint KEEP_CHECKPOINT]
                [--gpuid [GPUID [GPUID ...]]]
                [--gpu_ranks [GPU_RANKS [GPU_RANKS ...]]]
                [--world_size WORLD_SIZE] [--gpu_backend GPU_BACKEND]
                [--gpu_verbose_level GPU_VERBOSE_LEVEL]
                [--master_ip MASTER_IP] [--master_port MASTER_PORT]
                [--queue_size QUEUE_SIZE] [--seed SEED]
                [--param_init PARAM_INIT] [--param_init_glorot]
                [--train_from TRAIN_FROM]
                [--reset_optim {none,all,states,keep_states}]
                [--pre_word_vecs_enc PRE_WORD_VECS_ENC]
                [--pre_word_vecs_dec PRE_WORD_VECS_DEC] [--fix_word_vecs_enc]
                [--fix_word_vecs_dec] [--batch_size BATCH_SIZE]
                [--batch_type {sents,tokens}] [--pool_factor POOL_FACTOR]
                [--normalization {sents,tokens}]
                [--accum_count ACCUM_COUNT [ACCUM_COUNT ...]]
                [--accum_steps ACCUM_STEPS [ACCUM_STEPS ...]]
                [--valid_steps VALID_STEPS]
                [--valid_batch_size VALID_BATCH_SIZE]
                [--max_generator_batches MAX_GENERATOR_BATCHES]
                [--train_steps TRAIN_STEPS] [--single_pass] [--epochs EPOCHS]
                [--early_stopping EARLY_STOPPING]
                [--early_stopping_criteria [EARLY_STOPPING_CRITERIA [EARLY_STOPPING_CRITERIA ...]]]
                [--optim {sgd,adagrad,adadelta,adam,sparseadam,adafactor,fusedadam}]
                [--adagrad_accumulator_init ADAGRAD_ACCUMULATOR_INIT]
                [--max_grad_norm MAX_GRAD_NORM]
                [--dropout DROPOUT [DROPOUT ...]]
                [--attention_dropout ATTENTION_DROPOUT [ATTENTION_DROPOUT ...]]
                [--dropout_steps DROPOUT_STEPS [DROPOUT_STEPS ...]]
                [--truncated_decoder TRUNCATED_DECODER]
                [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
                [--label_smoothing LABEL_SMOOTHING]
                [--average_decay AVERAGE_DECAY]
                [--average_every AVERAGE_EVERY]
                [--src_noise {sen_shuffling,infilling,mask} [{sen_shuffling,infilling,mask} ...]]
                [--src_noise_prob SRC_NOISE_PROB [SRC_NOISE_PROB ...]]
                [--learning_rate LEARNING_RATE]
                [--learning_rate_decay LEARNING_RATE_DECAY]
                [--start_decay_steps START_DECAY_STEPS]
                [--decay_steps DECAY_STEPS]
                [--decay_method {noam,noamwd,rsqrt,none}]
                [--warmup_steps WARMUP_STEPS] [--report_every REPORT_EVERY]
                [--log_file LOG_FILE]
                [--log_file_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET,50,40,30,20,10,0}]
                [--exp_host EXP_HOST] [--exp EXP] [--tensorboard]
                [--tensorboard_log_dir TENSORBOARD_LOG_DIR]
                [--sample_rate SAMPLE_RATE] [--window_size WINDOW_SIZE]
                [--image_channel_size {3,1}]
train.py: error: the following arguments are required: --data/-data
